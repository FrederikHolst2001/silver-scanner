import requests
from bs4 import BeautifulSoup
import re

BASE = "https://www.guloggratis.dk"

def scrape_guloggratis():

    url = "https://www.guloggratis.dk/soeg?q=925 s√∏lv"

    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    deals = []

    try:

        r = requests.get(url, headers=headers, timeout=15)

        soup = BeautifulSoup(r.text, "lxml")

        links = soup.find_all("a", href=True)

        for link in links:

            text = link.get_text(" ").strip().lower()

            if len(text) < 10 or len(text) > 200:
                continue

            price_match = re.search(r'(\d+(?:[.,]\d+)?)\s?kr', text)
            weight_match = re.search(r'(\d+(?:[.,]\d+)?)\s?g', text)

            if not price_match or not weight_match:
                continue

            price = float(price_match.group(1).replace(",", "."))

            href = link["href"]

            if not href.startswith("http"):
                href = BASE + href

            deals.append({
                "title": text,
                "price": price,
                "link": href
            })

        print("GulogGratis deals found:", len(deals))

    except Exception as e:

        print("GulogGratis error:", e)

    return deals